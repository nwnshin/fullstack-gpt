{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.5, streaming=True, callbacks=[StreamingStdOutCallbackHandler()])\n",
    "\n",
    "poet_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a world-class nobel prized poet. You only create poems about programming languages. You are famous for using easy expressions in your poetry. Your poetry should be in english, and length should be min 100 words and max 500 words.\"),\n",
    "    (\"human\", \"Write a poem about {language}\")\n",
    "])\n",
    "\n",
    "poet_chain = poet_prompt | chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the world of code, a language stands tall,\n",
      "TypeScript, beloved by one and all.\n",
      "With types to guide and errors to catch,\n",
      "It makes programming a smoother match.\n",
      "\n",
      "No more guessing, no more fear,\n",
      "TypeScript whispers in your ear.\n",
      "\"Is that variable a string or a number?\n",
      "Let me help you, I won't let you slumber.\"\n",
      "\n",
      "Static typing, oh so divine,\n",
      "Makes your code robust and fine.\n",
      "No more runtime errors to dread,\n",
      "With TypeScript, your worries are shed.\n",
      "\n",
      "Classes, interfaces, generics galore,\n",
      "TypeScript offers so much more.\n",
      "A superset of JavaScript, it truly shines,\n",
      "In the land of programming, it defines.\n",
      "\n",
      "So raise your hands, give a cheer,\n",
      "For TypeScript, the language we hold dear.\n",
      "With its strong typing and modern flair,\n",
      "It's a programmer's dream, beyond compare.This poem celebrates TypeScript, a programming language highly regarded in the coding world. The poet praises TypeScript for its feature of \"types\" that help programmers identify and prevent errors in their code, making the coding process smoother and less stressful.\n",
      "\n",
      "The poet highlights how TypeScript eliminates the need for guesswork and fear in coding by providing clear guidance on variable types. The use of \"static typing\" is commended for making the code more robust and reducing the occurrence of runtime errors, offering a sense of relief to programmers.\n",
      "\n",
      "The poem mentions various features of TypeScript such as classes, interfaces, and generics, showcasing the language's versatility and richness compared to its base language, JavaScript. TypeScript is portrayed as a superior choice in the realm of programming due to its modernity and precision.\n",
      "\n",
      "Overall, the poem encourages readers to appreciate and celebrate TypeScript for its strong typing system and contemporary appeal, presenting it as a valuable tool that programmers cherish. It conveys a sense of admiration and gratitude towards TypeScript for simplifying the coding process and enhancing the quality of programs created with it."
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='This poem celebrates TypeScript, a programming language highly regarded in the coding world. The poet praises TypeScript for its feature of \"types\" that help programmers identify and prevent errors in their code, making the coding process smoother and less stressful.\\n\\nThe poet highlights how TypeScript eliminates the need for guesswork and fear in coding by providing clear guidance on variable types. The use of \"static typing\" is commended for making the code more robust and reducing the occurrence of runtime errors, offering a sense of relief to programmers.\\n\\nThe poem mentions various features of TypeScript such as classes, interfaces, and generics, showcasing the language\\'s versatility and richness compared to its base language, JavaScript. TypeScript is portrayed as a superior choice in the realm of programming due to its modernity and precision.\\n\\nOverall, the poem encourages readers to appreciate and celebrate TypeScript for its strong typing system and contemporary appeal, presenting it as a valuable tool that programmers cherish. It conveys a sense of admiration and gratitude towards TypeScript for simplifying the coding process and enhancing the quality of programs created with it.', additional_kwargs={}, response_metadata={'finish_reason': 'stop'}, id='run-04f6bc3a-c4a5-414c-97f8-42645ac7da8b-0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a professional poem analysist. You summarize and analyze poetry with easy expressions for middle school students. Length of your analysis should be max 350 words.\"),\n",
    "    (\"human\", \"{poem}\")\n",
    "])\n",
    "\n",
    "analysis_chain = analysis_prompt | chat\n",
    "\n",
    "final_chain = {\"poem\":poet_chain} | analysis_chain\n",
    "\n",
    "final_chain.invoke({\n",
    "    \"language\" : \"typescript\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human:Tesla\\nAI:\\n    This is what I know:\\n    Country : USA\\n    Industry : Automobile\\n    Address : Austin, Texas, USA\\n    Found : 2003\\n    Total Sales : 71.6 billion dollars (2023) appx\\n    Gross Profit : 17.66 billion dollars (2023)\\n    \\n\\nHuman: what do you know about LG'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import example_selector\n",
    "from langchain.prompts.example_selector.base import BaseExampleSelector\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.5, streaming=True, callbacks=[StreamingStdOutCallbackHandler()])\n",
    "\n",
    "# placeholder이름을 key변수로 사용함. \n",
    "examples = [\n",
    "    { \"company\":\"Inditex\",\n",
    "    \"reply\":\"\"\"\n",
    "    This is what I know:\n",
    "    Country : Spain\n",
    "    Industry : Fashion\n",
    "    Address : La Coruna, Spain\n",
    "    Found : 1985\n",
    "    Total Sales : 35.9 billion euros (2023)\n",
    "    Gross Profit : 20.8 billion euros (2023)\n",
    "    \"\"\"\n",
    "    }, {\n",
    "        \"company\":\"Tesla\",\n",
    "    \"reply\":\"\"\"\n",
    "    This is what I know:\n",
    "    Country : USA\n",
    "    Industry : Automobile\n",
    "    Address : Austin, Texas, USA\n",
    "    Found : 2003\n",
    "    Total Sales : 71.6 billion dollars (2023) appx\n",
    "    Gross Profit : 17.66 billion dollars (2023)\n",
    "    \"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "class RandomExampleSelector(BaseExampleSelector):\n",
    "    def __init__(self, examples):\n",
    "        self.examples = examples\n",
    "    # 직접 example selector을 만들면, 그 example selector은 add_example 메소드를 필수적으로 필요로 한다.\n",
    "    # Adds examples to your already existing examples...뭔 일을 하는 메소드인거지 대체\n",
    "    def add_example(self, example):\n",
    "        self.examples.append(example)\n",
    "    # select examples method\n",
    "    # 예시 리스트로부터 무작위로 한개의 예시를 골라 return함. return값은 list형식[]이어야 함.\n",
    "    def select_examples(self, input_variables):\n",
    "        from random import choice\n",
    "        return [choice(self.examples)]\n",
    "\n",
    "\n",
    "example_prompt = PromptTemplate.from_template(\"Human:{company}\\nAI:{reply}\")\n",
    "\n",
    "example_selector = RandomExampleSelector(\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt = example_prompt,\n",
    "    example_selector = example_selector,\n",
    "    suffix = \"Human: what do you know about {company}\",\n",
    "    input_variables = [\"company\"],\n",
    ")\n",
    "\n",
    "\n",
    "prompt.format(company=\"LG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the capital of Sweden'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import load_prompt\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.3, streaming=True, callbacks=[StreamingStdOutCallbackHandler()])\n",
    "\n",
    "prompt = load_prompt(\"./prompt.json\")\n",
    "\n",
    "prompt.format(country=\"Sweden\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n    \\n    you are a role playing assistant. and you are impersonating a cinderella\\n    \\n    \\n    This is an example of how you talk:\\n    Human: what are you doing right now?\\n    You: Oh, I'm cleaning the house! Look at me sweep!\\n    \\n    \\n    Start now!\\n    Human: What is your favorite food?\\n    You: \\n    \\n    \""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts.pipeline import PipelinePromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.3, streaming=True, callbacks=[StreamingStdOutCallbackHandler()])\n",
    "\n",
    "intro = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    you are a role playing assistant. and you are impersonating a {character}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# 위에서 placeholder로 설정한 캐릭터가 어떻게 말하는지 예시 제공\n",
    "example = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    This is an example of how you talk:\n",
    "    Human: {example_question}\n",
    "    You: {example_answer}\n",
    "    \"\"\"\n",
    ")\n",
    "# AI asistant가 우리의 텍스트를 완성해줄 예시\n",
    "start = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Start now!\n",
    "    Human: {question}\n",
    "    You: \n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "final = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    {intro}\n",
    "    {example}\n",
    "    {start}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "prompts = [\n",
    "    (\"intro\", intro), (\"example\",example),(\"start\",start)\n",
    "]\n",
    "\n",
    "full_prompt = PipelinePromptTemplate(final_prompt=final, pipeline_prompts=prompts)\n",
    "\n",
    "full_prompt.format(\n",
    "    character=\"cinderella\", example_question=\"what are you doing right now?\",\n",
    "    example_answer=\"Oh, I'm cleaning the house! Look at me sweep!\",\n",
    "    question=\"What is your favorite food?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, my favorite food is definitely pumpkin pie! It's so delicious and reminds me of the magical ball where I met my prince charming."
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Oh, my favorite food is definitely pumpkin pie! It's so delicious and reminds me of the magical ball where I met my prince charming.\", additional_kwargs={}, response_metadata={'finish_reason': 'stop'}, id='run-3fcc2049-213e-45d6-b238-11deeff459d4-0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = full_prompt | chat\n",
    "\n",
    "chain.invoke({\n",
    "    \"character\":\"cinderella\", \n",
    "    \"example_question\":\"what are you doing right now?\",\n",
    "    \"example_answer\":\"Oh, I'm cleaning the house! Look at me sweep!\",\n",
    "    \"question\":\"What is your favorite food?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.globals import set_llm_cache\n",
    "from langchain.cache import InMemoryCache\n",
    "\n",
    "# LLM에서 받은 답변은 모두 메모리에 캐싱된다. \n",
    "set_llm_cache(InMemoryCache())\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.3, streaming=True, callbacks=[StreamingStdOutCallbackHandler()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fullstack-gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
